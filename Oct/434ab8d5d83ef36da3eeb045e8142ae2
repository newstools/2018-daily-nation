If you are among the multitudes sceptical that computers might one day be trustworthy replacements for drivers, consider this: The National Highway Traffic Safety Administration says that 94 per cent of serious crashes are the result of human error. So yes, computers might prove to be safer at the controls. It’s not a high bar. The secret sauce of those computers becoming our chauffeurs is the ubiquitous force of artificial intelligence (AI), which is already active in virtual personal assistants and a bank’s customer-service chatbot. But it’s the automobile where AI could have a critical role for the greatest number of people. Few AI applications carry the responsibility of automotive safety systems, where actions must be carried out in nanoseconds and an ill-considered response might have costly consequences. Systems that marry microprocessors, sensors and software to make fully driverless cars possible are in the advanced stages of development, but experts say the leap from today’s computer-assisted driving — features like Tesla’s Enhanced Autopilot and Cadillac’s Super Cruise — to fully automated motoring that might render humans optional remains considerable. SAFETY AND CONVENIENCE Still, AI is already quietly making driving safer. Beyond the applications now found in new cars, typically in conveniences like the speech-recognition feature of infotainment systems, are the subsystems that make up the packages of safety features common largely in luxury vehicles. Enhancements like night vision, automatic emergency braking and lane keeping all depend on processors that use sensors and computer instructions to warn drivers of danger or act to avoid collisions. The term artificial intelligence, coined in the 1950s, is something of an unfortunate choice, at least in terms of the automobile. The intelligence within cars — that is, their ability to learn and to apply that knowledge — is far from artificial; it is hard-earned. It comes down to capable electronics, sensors and, especially, extensive training. “Training is like teaching our kids to drive, with rules, absolutes and best practices,” Glen De Vos, chief technology officer at Aptiv, said in a telephone interview. “Some rules are embedded in the system — never out-drive the free space around the vehicle, obey road signs — but as you move up the spectrum toward accident avoidance, a predictive capacity is necessary.” Aptiv, a spin-off from Delphi Automotive, an auto industry supplier, builds the data sets that a trained AI system depends on. Most of that data is accumulated on the road, acquired in videos to create the basic knowledge bank that computers draw on. In some cases, this work is done overseas to reduce costs, and suppliers can make use of basic image collections — known as a trained data set — obtained off the shelf from market-research organisations. DETAILED ANNOTATION The key to making the images useful is adding detailed annotation — instructions that specify, “This is a tree, this is a garbage can” — for the object recognition function that is vital to preventing collisions. The work is tedious and until recently, has been mainly a manual task, with up to 80 per cent of the work devoted to classifying images and cleansing data, said Sachin Lulla, IBM’s automotive leader. Data is also collected by radar, or lidar, its light-beam equivalent. A high degree of refinement of the data, covering every possible situation, is vital to assuring that the safety systems don’t issue excessive warnings, an annoyance that might lead a driver to ignore such signals. The collecting of data to inform automotive AI systems will be greatly improved by a coming generation of connected cars — 50 million communicating wirelessly with each other by 2020 — according to Lulla. The 350 megabytes of data per second generated by these cars, covering such things as local weather and road conditions, will be a huge benefit to the entire community of connected vehicles. Some of the tasks where AI takes an important role happen inside the car. Driver monitoring is a major component of advanced safety systems, with cameras mounted on the dashboard watching eye and head positions and even pulse rate through a steering-wheel sensor. The concept, IBM says, is to add context — the driver’s condition and degree of engagement — to complete the picture of the situation in the car and on the road. “Understanding the driver, through facial expressions of emotions, is important,” said Ola Bostrom, vice-president for research and patents at Veoneer, a spin-off from Autoliv, an auto safety supplier. “Cognitive load can also be assessed using eye motions. Attention to driving can be evaluated by whether people in the car are talking to one another or thinking about what to say.” The information, along with factors like pitch of voice and use of aggressive words, has multiple uses. Evaluations of alertness and fatigue based on AI analysis are already built into several car models, with dashboard warnings for countering stress and anger. When fully autonomous driving for privately owned vehicles becomes available, the potential for a car to sense a driver’s illness and head for a hospital becomes a reality. One of AI’s strengths is simple object recognition. “If you can solve a problem using a traditional method, it’s incredibly efficient,” said De Vos of Aptiv, referring to existing safety systems. “In the case of a vision system identifying a person standing next to the road, you can write a relatively simple rule to determine what should be done.” FASTER ANSWERS But when a problem becomes more complex, like when an obstacle is detected on the road during a snowstorm, the advantage of using AI is its ability to solve problems that are otherwise too complex for existing systems. AI simply gets answers a lot faster. Among the challenges in developing AI is its lack of transparency, said Kurt Lehmann, head of technology development at Continental, one of the largest suppliers to the auto industry. “A fundamental weakness of the systems is that it is a black box,” Lehmann said, referring to the challenge of analysing the actions of algorithms. “It is not always predictable, and you can’t always tell why a decision has been made, so robust training and validation are needed.” The demands of advanced driver- assistance systems do not necessarily have to be frozen at the time the car is built. Not only can software be updated, but self-learning algorithms can continuously raise the car’s AI by building relational connections, said Salah Hadi, Veoneer’s global director of vision systems. “Ideally, we want to have the system recognise an image it has never seen, like a person figuring out what an orangutan is because he knows what an ape looks like,” Hadi said. “This is the tuning part of developing AI and takes a lot of time.” The computing power it takes to operate a car with self-driving capability is staggering. A graphics processing unit to perform object recognition works at a computer speed of a trillion floating-point operations per second. The main processor’s performance is measured in millions of instructions per second. Stepping up from the partial automation of the Mercedes-Benz driver-assistance system to fully automated driving, which might require a car to have up to a dozen cameras, demands a hundredfold increase in computer power, and Veoneer says the requirement is increasing by a factor of three to five every other year. This does not come cheap. For the conditional automation known as Level 3, Aptiv estimates that the hardware — sensors, computer and communications gear — will cost $4,000 (Sh406,800) to $5,000 per car. That does not include software. While automakers have embraced the goal of eliminating all fatalities, deploying AI and autonomous vehicles can go only so far towards achieving that. A drunken driver of an older car could still blow through a stop sign, and road conditions will still be responsible for some collisions. So where are we on scale of true intelligence in cars? “I honestly believe we are still scratching the surface of applying the technologies of deep learning and neural networks,” said Lulla of IBM. “As computing increases, we will see this scale to true potential. The big issue is to perfect autonomous driving with human driving. Autonomous vehicles driving with other AVS seems far along, but when there is someone on a bike, it gets tricky.”   Mazda has a way of building cars that provide the right tactile feedback for the driver.