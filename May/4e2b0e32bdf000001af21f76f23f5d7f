Looking somewhat more comfortable than he usually does when talking to the press, Mark Zuckerberg admitted during his CNN interview that at the time of starting Facebook a few years back he had not at any point imagined that, a few years later, he would be talking about the role of his ground-breaking company in the integrity of elections, free speech, breach of data protection principles and terrorism. As a communications strategist, I loved the fact that the founder of the popular social network platform applied the classic tactics of crisis communications by readily and proactively admitting to the shortcomings of the company and presenting the remedies, right at the beginning of the interview, to the extent of ignoring what was asked by the questioner. But let’s dive a bit deeper. What is the hullabaloo all about? In a nutshell, Aleksandr Kogan, an academic psychologist and data scientist based at Cambridge University, deployed through Facebook a personality app that harvested data from millions of Facebook users around the world. CONSULTING FIRM Cambridge Analytica, a brand and political consulting firm, purchased the data harvested by Kogan and built a powerful software program that used the data to predict, and allegedly influence, voters’ choices at the US presidential ballot in favour of Donald Trump. At first glance, it would look like the only sin Facebook made was to make it possible for developers to deploy apps that its users can choose to use or not. So, what should we make of Zuckerberg’s apology? “This was a major breach of trust and I’m really sorry that this happened with a basic responsibility to protect peoples’ data and if we can do that then we deserve the opportunity to serve people,” said Zuckerberg. Was this admission of responsibility merely meant to mitigate the fast-growing #DeleteFacebook campaign on Twitter? Or is this more fundamental? INVENTIONS The position that Zuckerberg finds himself in seems to indicate that communities and entrepreneurs ought to reflect about the age-old question of the role of businesses in countries and communities. Is the sole purpose of entrepreneurship to deploy capital and promote innovation in the pursuit of profit or should they have an inherent responsibility to imagine the various scenarios that their innovations in businesses could create? Does the responsibility only lie with entrepreneurs or do societies also have a role to play in defining the future possible scenarios posed by inventions and innovations? Zuckerberg’s apology and personal admission of responsibility would seem to suggest that he believes entrepreneurs have a responsibility to imagine and plan for every scenario. But what does this say about the role of government regulation? REGULATION When asked what he thinks about being regulated, Zuckerberg indicated that he welcomes regulation, given that even the mainstream advertising space is regulated. But given the low level of industry-specific knowledge displayed by many of the senators who interviewed him, one could assume that it will continue to be hard for policy makers to get regulation right, making self-regulation the best option for technically complex and fast-paced sectors. To promote self-regulation, one would have to assume that the ethical views of society will be matched by those of the key players such the tech innovators, entrepreneurs and users themselves, but a user like Cambridge Analytica clearly has a different view of what is ethical conduct in regard to data privacy. Although no formal analyses or investigations have been carried out, neither firm has been found liable of any illegal activity or of having acted in a manner that is inconsistent with the business imperative to create products and return a profit for their shareholder. As such, the debate will find place in the ethical realm. DETRIMENTAL Three schools of thought could be considered: Those who believe that the very business model employed by Cambridge Analytica is unethical; those who believe that the ethical nature of their activities depends on whether their consequences are detrimental or not; and those who would rather look at the character of individuals behind the firms. Whichever school of thought, it is evident that is unlikely that there will be foolproof consensus anytime soon. What is certain, however, is that communities, governments and tech companies need to develop approaches for defining the possible scenarios that the various innovations could facilitate in order to avoid any perceived unethical use, particularly as we enter the era of artificial intelligence and machine learning. Mr Manirakiza is the CEO, Newmark Africa Group. gilbert@newmark-IMC.com  